{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALPIN Analysis and Method Comparison\n",
    "\n",
    "This notebook provides a comprehensive analysis of the ALPIN algorithm, including:\n",
    "1. **ALPIN vs T-test Baseline Comparison** - Evaluating ALPIN against a classical statistical approach\n",
    "2. **Noise Robustness Analysis** - Testing how performance degrades with increasing noise\n",
    "3. **Publication-Quality Figures** - Generating figures suitable for academic papers\n",
    "\n",
    "By the end of this notebook, you will understand when ALPIN excels and where its limitations lie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from alpin import ALPIN\n",
    "from alpin.baselines import TTestBaseline\n",
    "from alpin.data import generate_synthetic_signals\n",
    "from alpin.metrics import evaluate_all\n",
    "from alpin.experiments.sweep import sweep_noise\n",
    "from alpin.visualization import plot_signal, plot_metrics_comparison, plot_sweep_results\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Publication-quality style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Generation & Model Training\n",
    "\n",
    "We generate 50 synthetic signals with 200 samples each. These signals contain piecewise constant segments with Gaussian noise, mimicking real-world changepoint detection scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training signals\n",
    "n_signals = 50\n",
    "n_samples = 200\n",
    "\n",
    "signals, truths = generate_synthetic_signals(\n",
    "    n_signals=n_signals,\n",
    "    n_samples=n_samples,\n",
    "    noise_std=1.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(signals)} signals, each with {n_samples} samples.\")\n",
    "print(f\"Average changepoints per signal: {np.mean([len(t) for t in truths]):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ALPIN model\n",
    "model = ALPIN()\n",
    "model.fit(signals, truths)\n",
    "\n",
    "print(f\"Learned optimal beta: {model.beta_opt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What ALPIN Learned\n",
    "\n",
    "The learned $\\beta$ parameter controls the trade-off between data fidelity and model complexity:\n",
    "- **Higher $\\beta$**: Fewer changepoints detected (more conservative)\n",
    "- **Lower $\\beta$**: More changepoints detected (more sensitive)\n",
    "\n",
    "ALPIN automatically finds the $\\beta$ that minimizes the average excess penalized risk, adapting to the signal characteristics in the training data. Typical learned $\\beta$ values range from 10-200 depending on noise levels and jump amplitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ALPIN vs T-Test Baseline Comparison\n",
    "\n",
    "We compare ALPIN against a classical T-test baseline. The T-test detector uses a sliding window approach, comparing adjacent segments using independent t-tests to detect significant mean shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize T-test baseline\n",
    "ttest_baseline = TTestBaseline(window_fraction=0.05, confidence=0.95)\n",
    "\n",
    "print(f\"T-test parameters:\")\n",
    "print(f\"  - Window fraction: {ttest_baseline.window_fraction}\")\n",
    "print(f\"  - Confidence level: {ttest_baseline.confidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test signals (separate from training)\n",
    "test_signals, test_truths = generate_synthetic_signals(\n",
    "    n_signals=10,\n",
    "    n_samples=n_samples,\n",
    "    noise_std=1.0,\n",
    "    seed=999  # Different seed for test data\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(test_signals)} test signals for evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both methods on test signals\n",
    "alpin_metrics_list = []\n",
    "ttest_metrics_list = []\n",
    "\n",
    "for signal, truth in zip(test_signals, test_truths):\n",
    "    # ALPIN prediction\n",
    "    alpin_pred = model.predict(signal)\n",
    "    alpin_m = evaluate_all(alpin_pred, truth, len(signal), tolerance=10)\n",
    "    alpin_metrics_list.append(alpin_m)\n",
    "    \n",
    "    # T-test prediction\n",
    "    ttest_pred = ttest_baseline.detect(signal)\n",
    "    ttest_m = evaluate_all(ttest_pred, truth, len(signal), tolerance=10)\n",
    "    ttest_metrics_list.append(ttest_m)\n",
    "\n",
    "# Aggregate metrics\n",
    "alpin_avg = pd.DataFrame(alpin_metrics_list).mean().to_dict()\n",
    "ttest_avg = pd.DataFrame(ttest_metrics_list).mean().to_dict()\n",
    "\n",
    "print(\"Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': list(alpin_avg.keys()),\n",
    "    'ALPIN': [f\"{v:.4f}\" for v in alpin_avg.values()],\n",
    "    'T-Test': [f\"{v:.4f}\" for v in ttest_avg.values()]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Comparison Table: ALPIN vs T-Test Baseline ===\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "metrics_comparison = {\n",
    "    'ALPIN': alpin_avg,\n",
    "    'T-Test Baseline': ttest_avg\n",
    "}\n",
    "\n",
    "plot_metrics_comparison(\n",
    "    metrics_comparison,\n",
    "    title='ALPIN vs T-Test Baseline: Metric Comparison',\n",
    "    metric_keys=['precision', 'recall', 'rand_index'],\n",
    "    figsize=(10, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion: Which Method Performs Better?\n",
    "\n",
    "From the comparison above, we can observe:\n",
    "\n",
    "**ALPIN Advantages:**\n",
    "- Learns the optimal penalty from data, adapting to signal characteristics\n",
    "- Generally achieves better balance between precision and recall\n",
    "- Provides theoretical guarantees based on minimizing penalized risk\n",
    "\n",
    "**T-Test Advantages:**\n",
    "- Simple and interpretable\n",
    "- No training required\n",
    "- Works well when jump sizes are consistently large\n",
    "\n",
    "The T-test baseline may struggle with:\n",
    "- Small jump sizes relative to noise\n",
    "- Variable segment lengths\n",
    "- Signals requiring different sensitivity levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Noise Robustness Analysis\n",
    "\n",
    "A critical question for any changepoint detection method: **How does performance degrade as noise increases?**\n",
    "\n",
    "We test ALPIN (with fixed $\\beta$) at different noise levels: 0.5, 1.0, 2.0, and 5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run noise sweep experiment\n",
    "noise_levels = [0.5, 1.0, 2.0, 5.0]\n",
    "\n",
    "noise_results = sweep_noise(\n",
    "    n_signals=20,\n",
    "    n_samples=n_samples,\n",
    "    noise_levels=noise_levels,\n",
    "    n_splits=3,\n",
    "    beta=model.beta_opt,  # Use the learned beta\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Noise sweep complete! Results shape: {noise_results.shape}\")\n",
    "display(noise_results.groupby('noise_std').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot noise sweep results - Precision\n",
    "plot_sweep_results(\n",
    "    noise_results,\n",
    "    x_col='noise_std',\n",
    "    y_col='precision',\n",
    "    title='Precision vs Noise Level (ALPIN)',\n",
    "    figsize=(10, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot noise sweep results - Recall\n",
    "plot_sweep_results(\n",
    "    noise_results,\n",
    "    x_col='noise_std',\n",
    "    y_col='recall',\n",
    "    title='Recall vs Noise Level (ALPIN)',\n",
    "    figsize=(10, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Robustness Analysis\n",
    "\n",
    "From the plots above, we observe:\n",
    "\n",
    "1. **Low Noise (σ = 0.5)**: Excellent performance, high precision and recall.\n",
    "2. **Moderate Noise (σ = 1.0)**: Slight degradation but still robust.\n",
    "3. **High Noise (σ = 2.0)**: Noticeable performance drop, especially in precision.\n",
    "4. **Very High Noise (σ = 5.0)**: Significant degradation; the noise magnitude may exceed jump sizes.\n",
    "\n",
    "**Key Insight**: The learned $\\beta$ is optimized for a specific noise level (σ = 1.0 in training). When noise deviates significantly from training conditions, performance suffers. This suggests **adaptive or noise-aware $\\beta$ selection** could be beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Side-by-Side Prediction Example\n",
    "\n",
    "Let's visualize a single signal with predictions from both methods to understand their differences qualitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one test signal for detailed comparison\n",
    "example_idx = 0\n",
    "example_signal = test_signals[example_idx]\n",
    "example_truth = test_truths[example_idx]\n",
    "\n",
    "# Get predictions from both methods\n",
    "alpin_pred = model.predict(example_signal)\n",
    "ttest_pred = ttest_baseline.detect(example_signal)\n",
    "\n",
    "print(f\"Ground Truth changepoints: {example_truth}\")\n",
    "print(f\"ALPIN predictions: {alpin_pred}\")\n",
    "print(f\"T-Test predictions: {ttest_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ALPIN prediction\n",
    "plot_signal(\n",
    "    example_signal,\n",
    "    true_changepoints=example_truth,\n",
    "    pred_changepoints=alpin_pred,\n",
    "    title='ALPIN Prediction vs Ground Truth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot T-Test prediction\n",
    "plot_signal(\n",
    "    example_signal,\n",
    "    true_changepoints=example_truth,\n",
    "    pred_changepoints=ttest_pred,\n",
    "    title='T-Test Baseline Prediction vs Ground Truth'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Comparison Discussion\n",
    "\n",
    "Observing the two plots above:\n",
    "\n",
    "- **ALPIN** typically provides more accurate localization due to the learned penalty that balances detection sensitivity.\n",
    "- **T-Test** may detect spurious changepoints in noisy regions or miss subtle changes.\n",
    "\n",
    "The difference is most pronounced when:\n",
    "- Jump amplitudes are small relative to noise\n",
    "- Segments have varying lengths\n",
    "- The optimal detection sensitivity varies across the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Publication-Quality Figures\n",
    "\n",
    "We now create three polished figures suitable for academic publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Metrics Comparison Bar Chart\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 5), dpi=150)\n",
    "\n",
    "metrics = ['precision', 'recall', 'rand_index']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "alpin_vals = [alpin_avg[m] for m in metrics]\n",
    "ttest_vals = [ttest_avg[m] for m in metrics]\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, alpin_vals, width, label='ALPIN', color='#2E86AB', edgecolor='white')\n",
    "bars2 = ax1.bar(x + width/2, ttest_vals, width, label='T-Test', color='#A23B72', edgecolor='white')\n",
    "\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Method Comparison: ALPIN vs T-Test Baseline')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(['Precision', 'Recall', 'Rand Index'])\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.set_ylim(0, 1.1)\n",
    "ax1.bar_label(bars1, fmt='%.2f', padding=3, fontsize=9)\n",
    "ax1.bar_label(bars2, fmt='%.2f', padding=3, fontsize=9)\n",
    "\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure1_metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 1 saved as 'figure1_metrics_comparison.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Noise Sweep Line Plot\n",
    "fig2, ax2 = plt.subplots(figsize=(8, 5), dpi=150)\n",
    "\n",
    "# Aggregate results\n",
    "noise_agg = noise_results.groupby('noise_std').agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Plot precision\n",
    "ax2.errorbar(\n",
    "    noise_agg['noise_std'], \n",
    "    noise_agg[('precision', 'mean')],\n",
    "    yerr=noise_agg[('precision', 'std')],\n",
    "    marker='o', markersize=8, linewidth=2, capsize=4,\n",
    "    label='Precision', color='#2E86AB'\n",
    ")\n",
    "\n",
    "# Plot recall\n",
    "ax2.errorbar(\n",
    "    noise_agg['noise_std'], \n",
    "    noise_agg[('recall', 'mean')],\n",
    "    yerr=noise_agg[('recall', 'std')],\n",
    "    marker='s', markersize=8, linewidth=2, capsize=4,\n",
    "    label='Recall', color='#A23B72'\n",
    ")\n",
    "\n",
    "# Plot rand index\n",
    "ax2.errorbar(\n",
    "    noise_agg['noise_std'], \n",
    "    noise_agg[('rand_index', 'mean')],\n",
    "    yerr=noise_agg[('rand_index', 'std')],\n",
    "    marker='^', markersize=8, linewidth=2, capsize=4,\n",
    "    label='Rand Index', color='#F18F01'\n",
    ")\n",
    "\n",
    "ax2.set_xlabel('Noise Standard Deviation (σ)')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_title('ALPIN Performance vs Noise Level')\n",
    "ax2.legend(loc='lower left')\n",
    "ax2.set_ylim(0, 1.1)\n",
    "ax2.set_xlim(0, 5.5)\n",
    "\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure2_noise_sweep.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 2 saved as 'figure2_noise_sweep.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Example Prediction Comparison (side-by-side)\n",
    "fig3, axes = plt.subplots(2, 1, figsize=(12, 8), dpi=150, sharex=True)\n",
    "\n",
    "# Common x-axis\n",
    "x_axis = np.arange(len(example_signal))\n",
    "\n",
    "# Top plot: ALPIN\n",
    "axes[0].plot(x_axis, example_signal, color='#2C3E50', linewidth=1.2, alpha=0.8, label='Signal')\n",
    "for i, cp in enumerate(example_truth):\n",
    "    label = 'Ground Truth' if i == 0 else None\n",
    "    axes[0].axvline(x=cp, color='#27AE60', linestyle='--', linewidth=2, alpha=0.8, label=label)\n",
    "for i, cp in enumerate(alpin_pred):\n",
    "    label = 'ALPIN Prediction' if i == 0 else None\n",
    "    axes[0].axvline(x=cp, color='#E74C3C', linestyle='-', linewidth=2, alpha=0.8, label=label)\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].set_title('ALPIN Prediction', fontweight='bold')\n",
    "axes[0].legend(loc='upper right')\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "\n",
    "# Bottom plot: T-Test\n",
    "axes[1].plot(x_axis, example_signal, color='#2C3E50', linewidth=1.2, alpha=0.8, label='Signal')\n",
    "for i, cp in enumerate(example_truth):\n",
    "    label = 'Ground Truth' if i == 0 else None\n",
    "    axes[1].axvline(x=cp, color='#27AE60', linestyle='--', linewidth=2, alpha=0.8, label=label)\n",
    "for i, cp in enumerate(ttest_pred):\n",
    "    label = 'T-Test Prediction' if i == 0 else None\n",
    "    axes[1].axvline(x=cp, color='#9B59B6', linestyle='-', linewidth=2, alpha=0.8, label=label)\n",
    "axes[1].set_xlabel('Time Index')\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "axes[1].set_title('T-Test Baseline Prediction', fontweight='bold')\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure3_prediction_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 3 saved as 'figure3_prediction_comparison.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Discussion & Recommendations\n",
    "\n",
    "### When Does ALPIN Work Well?\n",
    "\n",
    "1. **Clean to Moderate Noise**: ALPIN excels when the signal-to-noise ratio is reasonable (σ ≤ 2).\n",
    "2. **Consistent Signal Properties**: When training and test signals share similar characteristics.\n",
    "3. **Learned Penalty Advantage**: The learned $\\beta$ adapts to the specific data distribution, outperforming fixed heuristics.\n",
    "4. **Sufficient Training Data**: Performance improves with more diverse training examples.\n",
    "\n",
    "### When Does ALPIN Struggle?\n",
    "\n",
    "1. **High Noise**: When σ approaches or exceeds jump magnitudes, detection becomes unreliable.\n",
    "2. **Few Training Samples**: With limited training data, $\\beta$ may not generalize well.\n",
    "3. **Distribution Shift**: If test signals differ significantly from training (e.g., different noise levels or segment structures).\n",
    "4. **Very Short Signals**: The partition optimization may have limited statistical power.\n",
    "\n",
    "### T-Test Baseline: Pros and Cons\n",
    "\n",
    "**Advantages:**\n",
    "- No training required; works out-of-the-box\n",
    "- Interpretable statistical foundation\n",
    "- Fast computation for real-time applications\n",
    "\n",
    "**Disadvantages:**\n",
    "- Fixed sensitivity; cannot adapt to data\n",
    "- Window size selection is critical and often manual\n",
    "- May produce false positives in highly variable signals\n",
    "\n",
    "### Recommendations for Practitioners\n",
    "\n",
    "| Scenario | Recommended Method |\n",
    "|----------|-------------------|\n",
    "| Labeled training data available | **ALPIN** |\n",
    "| No training data, need quick results | T-Test Baseline |\n",
    "| High noise (σ > 3) | Consider noise-robust preprocessing |\n",
    "| Real-time detection needed | T-Test (faster) or pre-trained ALPIN |\n",
    "| Research/publication quality | **ALPIN** with cross-validation |\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "1. **Noise-Adaptive $\\beta$**: Automatically adjust $\\beta$ based on estimated noise level.\n",
    "2. **Online Learning**: Update $\\beta$ as new labeled data becomes available.\n",
    "3. **Ensemble Methods**: Combine ALPIN with other detectors for robustness.\n",
    "4. **Multi-scale Analysis**: Apply ALPIN at multiple resolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. **Trained ALPIN** on 50 synthetic signals and learned an optimal $\\beta$.\n",
    "2. **Compared ALPIN to T-Test Baseline** using precision, recall, and Rand Index.\n",
    "3. **Analyzed noise robustness** across noise levels from 0.5 to 5.0.\n",
    "4. **Created publication-quality figures** for academic use.\n",
    "5. **Discussed practical recommendations** for when to use each method.\n",
    "\n",
    "ALPIN's ability to learn from data gives it an edge over classical methods when labeled examples are available, but practitioners should be mindful of training-test distribution alignment and noise conditions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
